# Live Lecture Processing System

## Project Overview

This project aims to transform live lecture audio into structured, insightful educational content using state-of-the-art technology. Our system captures live audio, converts it into text, preprocesses the data, summarizes it into concise class notes, stores the processed data, and finally visualizes the information for insights. The project leverages various technologies such as Google Cloud Speech-to-Text, Apache Spark, GPT models, MongoDB, and Tableau to ensure efficiency and scalability.

## Current Status

This project is currently under development. Key architectural decisions are being made to shape the software architecture, ensuring that each component integrates seamlessly and performs optimally. We are exploring various technologies and frameworks to find the best fit for each part of our system.

## Architecture Decision Records (ADRs)

We have documented several key architectural decisions in our ADRs. These decisions are crucial for the development and future scalability of our project. You can find more details about each decision in the following ADRs:

- [ADR 1: Choice of Speech-to-Text Service](ADR/ADR001.md)
- [ADR 2: Selection of Language Model API](ADR/ADR002.md)
- [ADR 3: Data Processing Framework](ADR/ADR003.md)
- [ADR 4: Database Selection for Storing Processed Data](ADR/ADR004.md)
- [ADR 5: Data Visualization Tool](ADR/ADR005.md)

## Contributing

We welcome contributions from developers and researchers interested in educational technology and data processing. If you would like to contribute to the project, please fork the repository and submit a pull request with your proposed changes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

